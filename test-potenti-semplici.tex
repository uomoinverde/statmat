
Lezione del 27/05, ultima modifica 03/06, Michele Nardin

\((X_1,\dots,X_n)\) campione casuale proveniente da una distribuzione
\(F_X(x;\theta)\), con \(\theta \in \Theta\). Vogliamo verificare un sistema di ipotesi parametriche
\begin{equation*}
  \begin{cases}
    H_0 \colon \theta = \theta_0 \\ H_1 \colon \theta = \theta_1
  \end{cases}
\end{equation*}
Il sistema di ipotesi è detto \emph{semplice} se esso dipende solamente dal valore di \(\theta\), cioè se le ipotesi determinano completamente la distribuzione della statistica.

Abbiamo visto che la funziona di massima verosimiglianza fornisce un "ordinamento" tra i valori assunti da \(\theta\), ossia una misura della preferenza di un valore rispetto ad un altro.
\begin{equation*}
  L(\mathbf{x};\theta) = \prod_{i=1}^n f_X(x_i;\theta)\mathbb{I}_S(x_i)
\end{equation*}
In particolare, il rapporto
\begin{equation*}
  \frac{L(\theta_1;\mathbf{x})}{L(\theta_0;\mathbf{x})}
\end{equation*}
che costituisce una statistica del rapporto di verosimiglianza, può fornire importanti informazioni sulla regione critica del test.


\section{Test più potenti date ipotesi semplici}

Ricordiamo che un test per la verifica d'ipotesi semplici riguardo ad un
parametro \(\theta\) di forma
\begin{equation*}
  \begin{cases}
    H_0 \colon \theta = \theta_0 \\ H_1 \colon \theta = \theta_1
  \end{cases}
\end{equation*}
restituisce una regione critica di rifiuto \(C_\alpha\); le
probabilità di commettere un errore sono restituite da
\begin{align*}
  \alpha &= \mathbb{P}(\text{rifiuto}\,H_0 \mid H_0) \\
  \beta  &= \mathbb{P}(\text{accetto}\,H_0 \mid H_1)
\end{align*}
Solitamente si agisce stabilendo un certo \emph{livello di significatività}
\(\alpha\) del test, da cui si determina la quantità \(1 - \beta\) detta
\emph{potenza} del test. La potenza di un test può essere interpretata
come funzione dell'ipotesi alternativa:
\begin{equation*}
  \beta(\theta_1) = \mathbb{P}(\text{accetto}\,H_0 \mid \theta = \theta_1).
\end{equation*}
Useremo la notazione: MP = most powerful e UMP = uniformly most powerful.\\

\begin{dfn}[test \textsc{mp}]
 Fissato \(\alpha \in (0,1)\), un test che minimizza \(\beta(\theta_1)\) è detto test \emph{più potente} di livello \(\alpha\) per la verifica d'ipotesi semplice contro alternativa semplice. 
\end{dfn}

Il nostro obiettivo sarà ovviamente quello di trovare tale test. Vediamo come i concetti visti fin'ora (soprattutto verosimiglianza e sufficienza) siano legati a quanto cerchiamo tramite il seguente

\begin{lem}[Neyman--Pearson]
Sia \((X_1,\dots,X_n)\) un campione casuale proveniente da una distribuzione di densità \(f_{X_i}(\mathbf{x}; \theta)\).
Sia inoltre

\begin{equation*}
  \begin{cases}
    H_0 \colon \theta = \theta_0 \\ H_1 \colon \theta = \theta_1
  \end{cases}
\end{equation*}

il sistema di ipotesi (entrambe semplici) da verificare. Indicata con \(L(\theta;\mathbf{x})\) la funzione di massima verosimiglianza, 
il test $MP_\alpha$ per la verifica di \(H_0\) ha regione critica (o di rifiuto) data da
\begin{equation*}
  C = \left\lbrace \mathbf{x} \in X \colon
      \frac{L(\theta_1;\mathbf{x})}{L(\theta_0;\mathbf{x})} > A
      \right\rbrace, \quad A \in \mathbb{R}_+
\end{equation*}
dove \(A\) è un valore costante, dipendente da \(\alpha{}\).
\end{lem}
\textbf{Nota:} tale risultato è abbastanza intuitivo: se $A$ è sufficientemente grande, 
quando si vede che $L(\vartheta_1;\vec{x}) \geq A \cdot L(\vartheta_0;\vec{x})$ 
è assurdo pensare che $\vartheta_0$ sia una scelta plausibile, in quanto lo è molto di più $\vartheta_1$!

\begin{proof}

Sia $C$ la regione critica del test (di livello $\alpha$) dato dal lemma, e sia $C^*$ la regione critica di un qualsiasi altro test (sempre di livello $\alpha$).

Per provare il lemma dobbiamo mostrare quindi che $\beta^* \geq \beta$ 
(che sono ovviamente le probabilità di errore del 2o tipo delle due regioni in considerazione)
(indicheremo nel seguito con $\overline{C}, \overline{C^*}$ i complementari delle regioni $C$ e $C^*$).
Notiamo subito che
$$\overline{C} = \overline{C} \cap ({C^*} \cup \overline{C^*}) = (\overline{C} \cap {C^*}) \cup (\overline{C} \cap \overline{C^*})$$
e che 
$$\overline{C}^* = \overline{C}^* \cap ({C} \cup \overline{C}) = (\overline{C}^* \cap {C}) \cup (\overline{C}^* \cap \overline{C})$$

\begin{align*}
\beta^* - \beta 
&= P(\vec{x} \in \overline{C}^* | \vartheta = \vartheta_1) 
	- P(\vec{x} \in \overline{C} | \vartheta = \vartheta_1)
\\ &= \int_{\vec{x} \in \overline{C}^* } L(\vartheta_1;\vec{x}) d \vec{x} 
	- \int_{\vec{x} \in \overline{C} } L(\vartheta_1;\vec{x}) d \vec{x}
\\ &= \int_{\vec{x} \in (\overline{C}^* \cap {C}) \cup (\overline{C}^* \cap \overline{C}) } L(\vartheta_1;\vec{x}) d \vec{x} 
	- \int_{\vec{x} \in (\overline{C} \cap {C^*}) \cup (\overline{C} \cap \overline{C^*}) } L(\vartheta_1;\vec{x}) d \vec{x}
\\ &= \int_{\vec{x} \in \overline{C}^* \cap C } L(\vartheta_1;\vec{x}) d \vec{x} 
	- \int_{\vec{x} \in \overline{C} \cap C^* } L(\vartheta_1;\vec{x}) d \vec{x}
\\ & \geq A \left[  \int_{\vec{x} \in \overline{C}^* \cap C } L(\vartheta_0;\vec{x}) d \vec{x} 
	- \int_{\vec{x} \in \overline{C} \cap C^* } L(\vartheta_0;\vec{x}) d \vec{x} \right]
\\ & = A \left[ \int_{\vec{x} \in (\overline{C}^* \cap {C}) \cup ({C}^* \cap {C}) } L(\vartheta_0;\vec{x}) d \vec{x} 
	- \int_{\vec{x} \in (\overline{C} \cap {C^*}) \cup ({C} \cap {C^*}) } L(\vartheta_0;\vec{x}) d \vec{x} \right]
\\ & = A \left[  \int_{\vec{x} \in C} L(\vartheta_0;\vec{x}) d \vec{x} 
	- \int_{\vec{x} \in C^* } L(\vartheta_0;\vec{x}) d \vec{x} \right]
\\ & = A ( \alpha - \alpha) = 0
\end{align*}

Da cui $\beta^* \geq \beta $
\end{proof}

\noindent \textbf{Importante:} Da nessuna parte abbiamo supposto che $\vartheta$ sia uno scalare, e guardando la dimostrazione notiamo che tale ipotesi sarebbe inutile: quindi (come al solito d'altronde) $\vartheta$ può benissimo essere un vettore di parametri incogniti!\\
\\