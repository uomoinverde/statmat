%%%%lezione 25 marzo%%%%

\section{Test di ipotesi}
Lezione del 25/03, ultima modifica 20/05, Andrea Gadotti
\\ \\

La procedura di test per la verifica di ipotesi che descriveremo a breve cerca di fornire una soluzione ai seguenti problemi:
\begin{enumerate}
\item Determinare quanto un'ipotesi è realistica, verosimile, compatibile con l'informazione empirica a disposizione.
\item Trovare un ragionamento oggettivo (matematico) per inferire dall'informazione disponibile (ovvero il contenuto di un campione) circa la veridicità dell'ipotesi formulata.
\item Misurare in qualche modo questa ''vicinanza'' tra ipotesi e realtà.
\end{enumerate}
Useremo statistiche pivot in ambito parametrico: la distribuzione da cui proviene il campione casuale $(X_1,...,X_n)$ è nota a meno di uno o più parametri.\\

\subsection{Tipi di ipotesi} 
Supponiamo di avere un campione casuale i.i.d.
\((X_1,\dots,X_n) \sim F_X(\mathbf{x}; \theta)\). Supponiamo che lo spazio \(\Theta{}\) in cui vive il parametro \(\theta{}\) sia partizionato in due sottoinsiemi \(\Theta_0, \Theta_1\). Le \emph{ipotesi} vengono poste nella forma:
\begin{equation}
  \begin{cases}
    H_0 \colon \theta \in \Theta_0 \\
    H_1 \colon \theta \in \Theta_1,
  \end{cases}
  \Theta = \Theta_0 \cup \Theta_1.
\end{equation}

Chiameremo \(H_0\) \emph{ipotesi nulla} e \(H_1\) \emph{ipotesi alternativa}. Idealmente, \(H_0\) rappresenta la conoscenza pregressa, la supposizione vera fino a prova contraria; invece, \(H_1\) costituisce l'ipotesi di lavoro, quella su cui ripieghiamo nel momento in cui il nostro test risulta in contraddizione con \(H_0\).

Il test si riduce a una \textit{regola di decisione} in merito a $H_0$ e $H_1$ sulla base del campione casuale $(X_1,...,X_n)$ da $X \sim F_X (x;\theta)$. Dividiamo lo spazio dei campioni in due regioni disgiunte: $C$ (regione critica del test) e $C^c$. La decisione può chiaramente essere corretta, ma anche errata, poiché il campione costituisce un'informazione non completa. Risulta quindi necessario formulare delle \textit{conclusioni in probabilità}, ovvero associare alla nostra conclusione la probabilità che questa sia corretta, cercando ovviamente di massimizzarla.\\
Possiamo riassumere le varie possibilità nella tabella e nel disegno sottostanti:
\\
\\
\begin{center}
\begin{tabular}{c||c|c}
  & \(H_0\) è \textbf{vera} & \(H_0\) è \textbf{falsa} \\ 
  \hline 
  \textbf{Rifiuto} \(H_0\) & errore di specie \textsc{i} & nessun errore \\ 
  \hline 
  \textbf{Non rifiuto} \(H_0\) & nessun errore & errore di specie \textsc{ii}
\end{tabular} 
\end{center}

\begin{center}
\includegraphics [width=12cm] {immagini/grafico_1.jpg}
\end{center}

\paragraph{Lancio di una moneta.}
Consideriamo il campione casuale \((X_1,...,X_n) \sim b(1,p)\) rappresentante
\(n\) lanci di una moneta. Vogliamo testare l'onestà della moneta, in particolare capire se essa è truccata per far uscire più frequentemente croce. In questo caso, ipotizzeremo:
\begin{equation*}
  \begin{cases}
    H_0 \colon p \ge \frac12  \\ H_1 \colon p < \frac12.
  \end{cases}
\end{equation*}
 e il numero di teste $S_n = \sum_{i=1}^n X_i$. Vorremmo stimare la probabilità che esca testa con la media campionaria $\overline{X}_n$. In questo caso potremmo avere:
\\
$$\bigg \{
\begin{array}{rl}
H_0: & p=1/2 \\
H_1: & p \neq 1/2 \\
\end{array}
$$
\\
La regola di decisione consiste quindi nel rifiutare $H_0$ se $(X_1,...,X_n) \in C$ e invece rifiutare $H_0$ se $(X_1,...,X_n) \in C^c$. Ci piacerebbe trovare una regola di decisione che permetta di minimizzare la probabilità di commettere errori di I o II tipo. Purtroppo questo non è possibile, per la natura stessa della relazione che corre tra gli errori di I e II tipo. Di seguito un esempio che ci dà un'idea del perché:\\

\noindent \textbf{Esempio} Consideriamo un campione casuale $(X_1,...,X_n)$ da $N(\mu,\sigma^2)$ con $\sigma^2$ noto. Supponiamo che le nostre due ipotesi siano:
\\
$$\bigg \{
\begin{array}{lcr}
H_0: & \mu=\mu_0 & \text{ovvero } N(\mu=\mu_0,\sigma^2) \\
H_1: & \mu=\mu_1 & \text{ovvero } N(\mu=\mu_1,\sigma^2) \\
\end{array}
$$
con $\mu_1 > \mu_0$.\\
\\
\begin{center}
\includegraphics [width=12cm] {immagini/grafico_2.jpg}
\end{center}

Consideriamo 
\begin{align*}
  \alpha :&= \mathbb{P}(\text{rifiutare}\,\,H_0\mid H_0\,\,\text{vera}) \\
  &= \mathbb{P}(\text{campione}\,\,\in C\mid H_0\,\,\text{vera}) \\
  &= \mathbb{P}(\text{il nostro campione è } \geq c \mid \text{la distribuzione corretta è quella di sinistra}) \\
  &= P(\text{commettere un errore di I tipo}).
  \intertext{e}
  \beta :&= P(\text{non rifiutare } H_0 \mid H_0 \text{ falsa}) \\
  &= P(\text{il nostro campione appartiene a } C^c \mid H_0 \text{ falsa}) \\
  &= P(\text{il nostro campione è } \leq c \mid \text{la distribuzione corretta è quella di destra}) \\
  &= P(\text{commettere un errore di II tipo})
 \end{align*}. 
(Nota: $\alpha$ è detto \emph{livello di significatività del test})\\
È evidente che non è possibile annullare contemporaneamente sia $\alpha$ che $\beta$.\\
La procedura si divide quindi in due passi: il primo consiste nel \textbf{fissare} $\alpha$, il secondo nell'individuare la regola di decisione che minimizza $\beta$, in modo da trovare un test \textit{ottimo}.\\
\\
\\