%%% lezione 18 marzo %%%
%%%in fondo lezione 21 marzo %%%


\noindent\textbf{Distribuzione esatta della statistica pivot: distribuzione t di Student}
\\ \\
Lezione del 18/03, ultima modifica 26/03, Michele Nardin
\\
\\
La distribuzione $t$ di Student con $\nu$ gradi di libertà è definita come 
$T=\frac{Z}{\sqrt{S^2 / \nu}}$ ove $Z \sim N(0,1)$ mentre $S^2 \sim \chi^2_\nu$ (chiquadro con $\nu$ gradi di libertà).
La funzione di densità è $$f_{t_\nu}(t,\nu)=\frac{\Gamma((\nu + 1)/2)}{\Gamma(\nu / 2)}
\frac{1}{\sqrt{\pi \nu}} \frac{1}{[1+t^2/\nu]^{\frac{v+1}{2}}} \mathbbm{1}_\mathbbm{R} (t)$$
tale funzione è simmetrica, ha la classica forma a campana come la normale, ma a differenza di quest'ultima ha le code più pesanti.
Risulta che la statistica pivot per la media in campioni poco numerosi 
\footnote{In realtà vale per tutti i campioni, è solo che da un certo punto in poi la differenza con la normale è davvero trascurabile! Sulle tavole si riporta solo per $\nu < 120$} (in caso di campionamento da normale) 
ha distribuzione esatta t di Student. Infatti 
$$Q=\frac{\overline{X}_n - \mu}{S_n / \sqrt{n}}=\frac{\frac{\overline{X}_n - \mu}{\sigma / \sqrt{n}}}{\sqrt{\frac{S^2_n}{\sigma^2}}}$$
troviamo al numeratore $\frac{\overline{X}_n - \mu}{\sigma / \sqrt{n}} \sim N(0,1)$, (grazie al fatto che le $X_i$ sono equi distribuite normalmente) 
mentre al denominatore abbiamo che 
$$\sqrt{\frac{S^2_n}{\sigma^2}}= \sqrt{\frac{(n-1)S^2_n}{(n-1) \sigma^2}}= \sqrt{\frac{H}{(n-1)}} $$
Abbiamo già dimostrato che $H=\frac{(n-1)S^2_n}{\sigma^2} \sim \chi^2_{n-1}$, quindi in definitiva al denominatore abbiamo la radice di una chiquadro diviso i suoi gradi di libertà, ovvero siamo proprio in presenza di una distribuzione t di Student.
\\ \\
\noindent\textbf{Osservazione importante:} Quindi, quando il campione casuale è poco numeroso, è conveniente usare i quantili della distribuzione t di student per costruire gli intervalli di confidenza. Per numerosità campionarie $n>30$, approssimare la distribuzione t di student con la distribuzione normale offre risultati soddisfacenti. Ricordiamo che per il tlc $Q\rightarrow N(0,1)$)
\\ \\
\noindent\textbf{Intervallo di confidenza esatto}
\\ \\
Fissato un livello di confidenza $1-\alpha$, consideriamo i quantili della distribuzione t di student (con n-1 gradi di libertà, ove n è la dimensione campionaria) 
$\pm t_{(\alpha/2;n-1)}$, 
troviamo $$ P\left(-t_{(\alpha/2;n-1)} \leq \frac{\overline{X}_n - \mu}{S_n / \sqrt{n}}
 \leq t_{(\alpha/2;n-1)}\right) = 1 - \alpha $$
Notiamo che questa volta vale l'uguaglianza 'vera', poiché non stiamo considerando approssimazioni asintotiche. 
In presenza del campione effettivamente estratto, $(x_1,...,x_n)$, 
scriviamo $\overline{x}_n$ e $s^2_n$ i valori assunti da media e varianza campionaria,
l'intervallo di confidenza è $$IC_{\mu}(1-\alpha)=
\left[\overline{x}_n -
 t_{(\alpha / 2;n-1)} 
 \sqrt{\frac{s^2_n}{n}},
  \overline{x}_n + t_{(\alpha / 2;n-1)}\sqrt{\frac{s^2_n}{n}}\right]$$
\begin{oss}
Alcune osservazioni che, pur sembrando banali, è bene tenere a mente:
\begin{enumerate}
\item Al crescere del livello di confidenza $(1-\alpha)$ e/o della varianza campionaria $S^2_n$ cresce anche l'ampiezza di IC
\item Al crescere dell'ampiezza campionaria $n$, (fermo restando il livello di confidenza) l'ampiezza di IC diminuisce
\end{enumerate}
\end{oss}

\noindent\textbf{Intervalli di confidenza per la varianza}
\\ \\
Sia \((X_1,\dotsc,X_n)\) un campione casuale da $N(\mu,\sigma^2)$.
Consideriamo la statistica pivot $$W=\frac{n-1}{\sigma^2} S^2_n$$ Abbiamo già mostrato che $W \sim \chi^2_{n-1}$. 
Ma allora, dato che noi cerchiamo $q_1,q_2$ t.c. 
$$P \left( q_1 \leq \frac{n-1}{\sigma^2} S^2_n \leq q_2 \right) =1-\alpha$$ 
troviamo che essi sono i quantili di ordine $\alpha / 2$ e $1 - \alpha / 2$ della chiquadro con n-1 gradi di libertà, che indicheremo $q_1=\chi^2_{(n-1,\alpha / 2)}$ e $q_2=\chi^2_{(n-1,1 - \alpha / 2)}$.
Con qualche passaggio otteniamo:
$$P \left( \frac{1}{q_2} \leq \frac{\sigma^2}{(n-1) S^2_n} \leq \frac{1}{q_1} \right) =1-\alpha$$
$$P \left( \frac{(n-1) S^2_n}{q_2} \leq \sigma^2 \leq \frac{(n-1) S^2_n}{q_1} \right) =1-\alpha$$
Troviamo così l'intervallo casuale (e di conseguenza il relativo intervallo di confidenza, una volta estratto il campione e trovato un valore a $S^2_n$) $$IC=\left[ \frac{(n-1)S^2_n}{q_2};\frac{(n-1)S^2_n}{q_1} \right]$$
\\ \\
\subsection{Intervallo di confidenza per differenza di medie}

Vogliamo confrontare due distribuzioni: \textit{sintetizziamo} la differenza tra due popolazioni tramite la differenza delle loro media.

Supponiamo di avere raccolto due campioni casuali indipendenti
\((X_1,\dotsc,X_n)\) e \((Y_1,\dotsc,Y_m)\) provenienti da distribuzioni \(D_X\) e \(D_Y\) di medie \(\mu_X\), \(\mu_Y\) ignote e deviazioni standard \(\sigma_X\), \(\sigma_Y\) note.

Per stimare le medie delle due popolazioni, possiamo ricorrere alle medie campionarie \(\bar{X}_n\) e \(\bar{Y}_m\). Volendo determinare un intervallo di confidenza per \(\Delta := \mu_X - \mu_Y\), osserviamo i seguenti fatti:
\begin{enumerate}
  \item La variabile casuale \(\hat{\Delta} := \bar{X} - \bar{Y}\) avrà valore atteso \(\Delta\) e varianza
  \begin{equation*}
    \var(\hat{\Delta}) = \frac{\sigma_X^2}{n} + \frac{\sigma_Y^2}{m},
  \end{equation*}
  grazie all'assunzione di indipendenza dei due campioni casuali.
  \item La funzione
  \begin{equation*}
    Z := \frac{(\bar{X}-\bar{Y}) - (\mu_X - \mu_Y)}{\sqrt{n^{-1}\sigma_X^2+m^{-1}\sigma_Y^2}}
  \end{equation*}
  risulta essere statistica pivot per \(\Delta\).
  \item Per il teorema del limite centrale, \(Z\) ha distribuzione asintotica Normale standard indipendentemente dalla distribuzione di \(X\) e \(Y\). Ciò ci consente, per campioni di grandi dimensioni, di determinare un'intervallo di confidenza approssimato.
\end{enumerate}
L'intervallo di confidenza approssimato avrà forma
\begin{equation}
  \mathrm{IC}_{\Delta}(1-\alpha) \colon
  \left[(\bar{x} - \bar{y}) - z_{\alpha/2} \sqrt{ \frac{\sigma_X^2}{n} + \frac{\sigma_Y^2}{m}},(\bar{x} - \bar{y}) + z_{\alpha/2} \sqrt{ \frac{\sigma_X^2}{n} + \frac{\sigma_Y^2}{m}}\right]
\end{equation}

Al posto delle varianze possiamo usare anche gli stimatori corretti e consistenti varianza campionaria, e giungere allo stesso risultato per il teorema di Slutsky.
\\ \\
In generale non conosciamo la varianza delle distribuzioni: in base al problema che dobbiamo affrontare, può essere plausibile supporre di conoscere la distribuzione delle due popolazioni a meno di uno o più parametri.

\paragraph{Location Model.} Supponiamo di avere a disposizione due campioni casuali indipendenti \((X_1,\dotsc,X_n)\) e \((Y_1,\dotsc,Y_m)\) provenienti da distribuzioni Normali di parametri ignoti, con l'unica informazione che \(\sigma_X^2 = \sigma_Y^2 = \sigma^2\). Differentemente da quanto fatto prima, non è possibile normalizzare \(\hat{\Delta} = \bar{X} - \bar{Y}\) ottenendo una statistica pivot.
Tuttavia, considerando le varianze campionarie \(S_X^2\) e \(S_Y^2\), possiamo ottenere una statistica pivot i cui percentili sono tabulati: in particolare, ricaviamo una statistica avente distribuzione \(t\)-Student.
Le informazioni a disposizione sono le seguenti:
\begin{enumerate}
  \item \(\frac{(n-1)S_X^2}{\sigma^2} \sim \chi_{n-1}^2\) e
  \(\frac{(m-1)S_Y^2}{\sigma^2} \sim \chi_{m-1}^2\);
  \item
  \begin{equation*}
    Z := \frac{\hat{\Delta}-\Delta}{\sqrt{\frac{\sigma_X^2}{n} + \frac{\sigma_Y^2}{m}}}
    = \frac{\hat{\Delta} - \Delta}{\sigma\sqrt{\frac{1}{n}+\frac{1}{m}}}
    \sim N(0,1)
  \end{equation*}
\end{enumerate}
Ora, definiamo la seguente variabile casuale, detta \emph{pooled variance}:
\begin{equation}
  S_p^2 := \frac{(n - 1)S_X^2 + (m - 1)S_Y^2}{n + m - 2}
\end{equation}
la quale risulta essere uno stimatore corretto e consistente di \(\sigma^2\). Inoltre,
\begin{equation*}
  \frac{(n+m-2)S_p^2}{\sigma^2} \sim \chi_{n+m-2}^2.
\end{equation*}
Ora, possiamo finalmente definire una statistica pivot:
\begin{equation}
  T := \frac{Z}{\sqrt{\frac{S_p^2(n+m-2)}{\sigma^2(n+m-2)}}} =
  \frac{\hat{\Delta}-\Delta}{S_p\sqrt{\frac{1}{n} + \frac{1}{m}}}
  \sim t_{n+m-2}
\end{equation}
per cui ci è possibile costruire un intervallo di confidenza per \(\Delta\), essendo la distribuzione \(t\)-Student tabulata.
Ricalcando i passaggi delle applicazioni precedenti, fissato $\alpha$  troviamo l'intervallo casuale per $\Delta$.
\begin{equation}
  \mathrm{IC}_{\Delta}(1-\alpha) \colon
  \left[(\bar{x} - \bar{y}) - t_{n+m-2;\alpha/2}\, S_p\sqrt{ \frac{1}{n} + \frac{1}{m}},(\bar{x} - \bar{y}) t_{n+m-2;\alpha/2}\, S_p\sqrt{ \frac{1}{n} + \frac{1}{m}}\right]
\end{equation}


\subsection{Intervallo di confidenza per la differenza di proporzioni}

Supponiamo di avere \((X_1,\dotsc,X_n)\) da distribuzione \(b(1,p_X)\), con stimatore \(\hat{p}_X\) e \((Y_1,\dotsc,Y_m)\) da distribuzione \(b(1,p_Y)\), con stimatore \(\hat{p}_Y\). Supponiamo che i due campioni siano tra loro indipendenti. Allora
\begin{equation}
  \Delta := \hat{p}_X - \hat{p}_Y \stackrel{a}{\sim}
  N\left(p_X - p_Y, \frac{p_X(1-p_X)}{n} + \frac{p_Y(1-p_Y)}{m}\right).
\end{equation}
 quindi usando la statistica Pivot 
\begin{equation*}
  Z := \frac{(\hat{p}_X - \hat{p}_Y) - (p_X - p_Y)}{\sqrt{\frac{p_X(1-p_X)}{n} + \frac{p_Y(1-p_Y)}{m}}} \stackrel{a}{\sim} N(0,1)
\end{equation*}
trovo l'intervallo di confidenza, utilizzando gli stimatori campionari già introdotti per definire gli estremi dell'intervallo:
\begin{equation*}
  \mathrm{IC}_{\Delta}(1-\alpha) \colon \hat{p}_X - \hat{p}_Y \pm
  z_{\alpha/2}\sqrt{\frac{\hat{p}_X(1-\hat{p}_X)}{n} + \frac{\hat{p}_Y(1-\hat{p}_Y)}{m}}
\end{equation*}